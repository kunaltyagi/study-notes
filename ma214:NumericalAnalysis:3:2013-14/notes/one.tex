\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{fullpage}
\usepackage{lastpage}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage[margin=3cm]{geometry}
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.05in}
\title{Notes}

% Edit these as appropriate
\newcommand\course{MA 214}
\newcommand\semester{autumn 2014}  % <-- current semester
\newcommand\asgnname{Notes}         % <-- assignment name
\newcommand\yourname{Kunal Tyagi}  % <-- your name
\newcommand\login{kunaltyagi}          % <-- your CS login

\newenvironment{answer}[1]{
  \subsubsection*{%some prelude
  \asgnname.#1}
}{\newpage}

\pagestyle{fancyplain}
\headheight 35pt
\lhead{\yourname\ (\login)\\\course\ --- \semester}
\chead{\textbf{\Large MA \asgnname}}
\rhead{\today}
\headsep 10pt

\begin{document}

\begin{answer}{Introduction}
    \begin{itemize}
        \item $ N = \pm (0.d_0 d_1 \ldots d_n)_\beta \beta^e$, here we have a number N with n significant digits in base $\beta$, with \textbf{exponent} as e and $(0.d_0 d_1 \ldots d_n)_\beta$ as \textbf{mantissa}
        \item If $x^*$ is approx. for x, then 
        \begin{itemize}
            \item $\mid x-x^* \mid$ is \textbf{Absolute Error} (AE)
            \item $\mid \frac{x-x^*}{x} \mid$ is the \textbf{Relative Error} (RE)
            \item RE can be approximated if x$\approx x^*$ by $\mid \frac{x-x^*}{x^*} \mid$ since $\frac{\alpha}{1-\alpha} \approx \alpha$ if $\alpha \ll$ 1
        \end{itemize}
        \item $x^*$ approximates x to t significant digits if RE is $\le 5 \times 10^{-t}$
        \item Loss of Significant Digits is caused by 
        \begin{itemize}
            \item addition/subtraction of quantities of nearly same value
            \item multiplication by a very large number
            \item division by a number very close to zero
        \end{itemize}
        \item To cure this, try to multiply with denominator/numerator's complement
        \item \textbf{Error Propagation}
        \begin{itemize}
            \item \textbf{Condition/Sensitivity} = max{$\mid \frac{f(x)-f(x^*)}{f(x)}\mid \div \mid \frac{x-x^*}{x} \mid$} for small RE. It is $\approx \mid \frac{f'(x)x}{f(x)}\mid$. The larger the number, the more the function is \textbf{ill-conditioned}
            \item \textbf{Instability}: Error of one step carries forward in next step and is magnified. It is the sensitivity of numerical process for calculation of f(x) from x to the inevitable rounding error commited during it.\\
            The effects can be reduce by considering the rounding off error one at a time
        \end{itemize}
        \item \textbf{Indermediate Value Theorem (IVT) for Continuous functions}: For all $f_{min}(x) \le F \le f_{max}(x)$, there exists at least one point c $\in$ [a,b]
        \item Use it in addition of $f(x_i)$ and in integration, where the sign of multiplicand of f(x) doesn't change \textbf{IMPORTANT}
        \item Recap: \textbf{Taylor's Theorem}: \\
        $f(x) = f(c)+f'(c)(x-c)+\frac{f''(c)}{2}(x-c)^2 + \ldots + \frac{f^{(n)}}{n!}(x-c)^n + R_{n+1}(x)$,\\
        where, $R_{n+1}(x)=\frac{1}{n!}\int _c^x (x-s)^n f^{(n+1)}(s) ds$
        \item Between $\{\alpha _n\}_{n \ge 1}$ and $\{\beta _n\}_{n \ge 1}$, $\alpha _n$ is Big-Oh $\beta _n$ if $\mid \alpha _n \mid \le \mid k\beta _n \mid \iff \alpha _n = \Theta(\beta _n)$ for some k and all sufficiently large n
        \item $\alpha _n$ is Little-Oh $\beta _n$ if $lim_{n\to \infty} \frac{\alpha _n}{\beta _n} = 0$
        
    \end{itemize}
\end{answer}

\begin{answer}{Polynomials, Intrapolation}
\begin{itemize}
    \item P(x) of degree n has at most n real roots, and has n Complex roots.
    \begin{itemize}
        \item \textbf{Power form}: $P(x) = a_0 + a_1x + \ldots + a_nx^n$
        \item \textbf {Nested Multiplication form}: $P(x) = a_0 + (x-c)(a_1+ (x-c)(\ldots+(x-c)(a_n)))$
    \end{itemize}
    \item Nested Multiplication form gives less round-off errors than Power form which can also result in loss of significant digits
    \item Power form also takes more multiplication and addition operations
    \item \textbf {Interpolation}
    \begin{itemize}
        \item \textbf{Weierstrass Approximaition}: if f(x) is continuous, for any $\epsilon$>0, there is a polynomial P(x) such that $\mid f(x)-P(x)\mid <\epsilon$ for all x in [a,b]
        \item Taylor Polynomial
        \item Lagrange Polynomial
        \item Newton's Piecewise Interpolation
        \item Cubic Spline
        \begin{itemize}
            \item Clamped boundary
            \item Free boundary
        \end{itemize}
        \item Natural Cubic Spline
    \end{itemize}
\end{itemize}
\end{answer}

\begin{answer}{Integration, Extrapolation}
\begin{itemize}
    \item Basic 5-6 methods
    \item \textbf{Composite Rules}
    \begin{itemize}
        \item \textbf{Composite Trapezoidal Rule}: \\
        \[
            \textbf{Formula} T_N = \frac{h}{2} [f(x_0 + 2\sum _{i=1}^{N-1}f(x_i) + f(x_N)]
        \] \[
            \textbf{Error} = -\frac{f''(\xi)h^2(b-a)}{12}
        \]
        \item \textbf{Composite Simpson's Rule}: \\
        \[
            \textbf{Formula}  T_N = \frac{h}{6} [f(x_0 + 2\sum _{i=1}^{N-1}f(x_i) + 4\sum _{i=1}^N f(x_{i-1}+h/2) +f(x_N)]
        \] \[
            \textbf{Error} = -\frac{f^{(4)}(\xi)(\frac{h}{2})^2(b-a)}{180}
        \]
    \end{itemize}
    \item \textbf{Richardson Extrapolation}: $M = N(h) + k_1h + k_2h^2 + k_3h^3 \ldots$ with unknown $k_i$ and all h as h $\to$ 0\\
    M $\approx$ N(h) is O(h) approximation. Extrapolation combines O(h) approx. to produce formulae with higher truncation error. To get higher order approx. substitute h as h/2 and remove the next order term.
    \begin{itemize}
        \item O(h) approx: M$\approx N_1(h)$, $N_1$(h) = N(h) + kh + $\ldots$
        \item O($h^2$) approx: M$\approx N_2$(h) = $N_1(\frac{h}{2})+[N_1(\frac{h}{2})-N_1(N)] + kh^2 + \ldots$
        \item O($h^i$) approx: M$\approx N_i$(h) = $N_{i-1}(\frac{h}{2}) + \frac{N_{i-1}(h/2) - N_{i-1}(h)}{2^{j-1} - 1}$
        \item O($h^{2i}$) approx: M$\approx N_i$(h) = $N_{i-1}(\frac{h}{2}) + \frac{N_{i-1}(h/2) - N_{i-1}(h)}{4^{j-1} - 1}$
    \end{itemize}
    \item \textbf{Romberg Integration}:
    \begin{itemize}
        \item For even N in Composite Trapezoidal rule, $T_N = \frac{T_{N/2}}{2} + h\sum _{i=1}^{N/2} f(a+(2i-1)h)$
        \item $O(h^{2m+2}$ approx. is $T_N^m = T_N^{m-1} + \frac{T_N^{m-1} - T^{m-1}_{N/2}}{4m -1}$
        \item For $T_M^m$ to be defined, $N/2^m$ has to be an integer
    \end{itemize}
    
\end{itemize}
\end{answer}

\begin{answer}{Numerical Differentiation}
\begin{itemize}
    \item If $f(x) = P_k(x) + f[ x_0, x_1, \ldots, x_k, x ]\Psi_k$(x), where $P_k(x)$ interpolates f(x) at $x_i$ and $\Psi_k(x) = \prod_{i=0}^k(x-x_i)$, then
    \item f'(x) = $P'_k(x) + f[ x_0, x_1, \ldots, x_k, x, x]\Psi_k(x) + f[ x_0, x_1, \ldots, x_k ]\Psi '_k(x)$
\end{itemize}
\end{answer}

\end{document}
